{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 다운로드 완료: pdf_files\\2024-09-27_Global Platform Weekly(9월 4주차).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-27_Global Consumer Weekly(9월 4주차).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-27_마켓 레이더 (9월 27일, 오전).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-27_Global Daily (9월 27일).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-27_Global 헬스케어 Weekly(9월 4주차).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-27_Global Japan Weekly (9월 4주차).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-27_Global IT H_W Weekly (9월 4주차).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-27_국내 주식 마감 시황 - 9월 26일.pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-26_Global 신재생 Weekly (9월 4주차).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-26_마켓레이더(9월 26일, 오전).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-26_Global Daily (9월 26일).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-26_국내 주식 마감 시황 - 9월 25일.pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-25_마켓레이더(9월 25일, 오전).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-25_Global Daily (9월 25일).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-25_국내 주식 마감 시황 - 9월 24일.pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-24_마켓레이더(9월 24일, 오전).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-24_Global Daily (9월 24일).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-24_Daily 신한생각 (9월 24일).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-24_국내 주식 마감 시황 - 9월 23일.pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-23_마켓레이더(9월 23일, 오전).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-23_Global Daily (9월 23일).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-23_국내 주식 마감 시황 - 9월 20일.pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-20_마켓레이더(9월 20일, 오전).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-20_Global Daily (9월 20일).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-20_Global Platform Weekly(9월 3주차).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-20_Global 헬스케어 Weekly(9월 3주차).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-20_Global 신재생 Weekly (9월 3주차).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-20_Global Consumer Weekly(9월 3주차).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-20_Global Japan Weekly(9월 3주차).pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-20_국내 주식 마감 시황 - 9월 19일.pdf\n",
      "파일 다운로드 완료: pdf_files\\2024-09-20_Global IT H_W Weekly (9월 3주차).pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "class ReportScraper:\n",
    "    def __init__(self, broker_code: int, report_type: str, start_date: str, end_date: str) -> None:\n",
    "        self.url = \"https://finance.naver.com/research\"\n",
    "        self.broker_code = broker_code  # 예: 신한투자증권(21)\n",
    "        self.report_type = report_type + \".naver\"  # 시황정보(market_info_list)\n",
    "\n",
    "        # 날짜 범위 설정\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "\n",
    "    def _convert_to_date(self, date_str: str) -> datetime.date:\n",
    "        \"\"\"Convert a date string to a datetime.date object.\"\"\"\n",
    "        date_format = \"%Y-%m-%d\"\n",
    "        return datetime.strptime(date_str, date_format).date()\n",
    "    \n",
    "    def collect_reports(self) -> list:\n",
    "        \"\"\"Collect reports within the set date range and return the report list.\"\"\"\n",
    "        # 보고서 리스트 수집\n",
    "        report_list = self._get_report_list()\n",
    "        return report_list\n",
    "\n",
    "    def _get_report_list(self) -> list:\n",
    "        \"\"\"Collect PDF metadata within the set date range.\"\"\"\n",
    "        base_url = f\"{self.url}/{self.report_type}?&searchType=brokerCode&brokerCode={self.broker_code}\"\n",
    "        page = 1\n",
    "        metadata = []\n",
    "\n",
    "        while True:\n",
    "            # URL에 페이지 번호 추가\n",
    "            url = f\"{base_url}&page={page}\"\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            table = soup.find('table')  # 해당 테이블의 class 이름에 따라 조정 가능\n",
    "\n",
    "            # 테이블 내 각 행을 순회\n",
    "            for row in table.find_all('tr'):\n",
    "                cells = row.find_all('td')\n",
    "                if len(cells) == 5:  # 필요한 데이터가 있는 행만 처리\n",
    "                    title = cells[0].text.strip()\n",
    "                    broker = cells[1].text.strip()\n",
    "                    file_link = cells[2].find('a')['href'] if cells[2].find('a') else None\n",
    "                    date = cells[3].text.strip()\n",
    "                    views = cells[4].text.strip()\n",
    "                    \n",
    "                    # 스크래핑된 날짜를 YYYY-MM-DD 형식으로 변환\n",
    "                    current_date = self.convert_to_long_format(date)\n",
    "\n",
    "                    # 최신 날짜(start_date) 이후의 데이터는 스킵\n",
    "                    if self.start_date < current_date:\n",
    "                        continue\n",
    "                    # 종료 날짜(end_date) 이전의 데이터는 수집 중단\n",
    "                    if self.end_date > current_date:\n",
    "                        return metadata\n",
    "                    \n",
    "                    # 데이터를 딕셔너리로 저장 (날짜는 YYYY-MM-DD 형식으로 저장)\n",
    "                    data = {\n",
    "                        'title': title,\n",
    "                        'broker': broker,\n",
    "                        'file_link': file_link,\n",
    "                        'date': current_date,  # 이미 YYYY-MM-DD 형식으로 변환됨\n",
    "                        'views': views\n",
    "                    }\n",
    "                    \n",
    "                    # 리스트에 추가\n",
    "                    metadata.append(data)\n",
    "\n",
    "            # 다음 페이지가 있는지 확인하고 없으면 루프 종료\n",
    "            next_page = soup.find('td', class_='pgRR')\n",
    "            if not next_page:\n",
    "                break\n",
    "\n",
    "            page += 1\n",
    "\n",
    "        return metadata\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_to_long_format(date_str: str) -> str:\n",
    "        \"\"\"Convert YY.MM.DD format to YYYY-MM-DD format.\"\"\"\n",
    "        return datetime.strptime(date_str, '%y.%m.%d').strftime('%Y-%m-%d')\n",
    "\n",
    "    def _download_pdf(self, metadata: dict, save_folder: str) -> None:\n",
    "        \"\"\"Download a PDF from the metadata and save it to the folder.\"\"\"\n",
    "        # 날짜와 제목을 기반으로 파일명 생성\n",
    "        date = metadata['date']\n",
    "        title = self._clean_filename(metadata['title'])  # 제목에 불법 문자 정리\n",
    "\n",
    "        # 파일명 형식: {날짜}_{제목}.pdf\n",
    "        filename = f\"{date}_{title}.pdf\"\n",
    "        file_path = os.path.join(save_folder, filename)\n",
    "\n",
    "        # PDF 파일 다운로드\n",
    "        pdf_url = metadata['file_link']\n",
    "        response = requests.get(pdf_url)\n",
    "\n",
    "        # 응답이 성공적이면 파일 저장\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"파일 다운로드 완료: {file_path}\")\n",
    "        else:\n",
    "            print(f\"파일 다운로드 실패: {pdf_url}\")\n",
    "\n",
    "    def _clean_filename(self, filename: str) -> str:\n",
    "        \"\"\"Replace illegal characters in the filename.\"\"\"\n",
    "        return filename.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "\n",
    "    def download_reports(self, report_list: list, save_folder: str) -> None:\n",
    "        \"\"\"Download each report in the provided report list.\"\"\"\n",
    "        # 저장할 폴더 생성\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "\n",
    "        # 각 보고서를 다운로드\n",
    "        for metadata in report_list:\n",
    "            self._download_pdf(metadata, save_folder)\n",
    "\n",
    "# 클래스 사용 예시\n",
    "scraper = ReportScraper(broker_code=21, report_type=\"market_info_list\", start_date=\"2024-09-27\", end_date=\"2024-09-20\")  # 날짜 범위와 함께 초기화\n",
    "report_list = scraper.collect_reports()  # 보고서 수집\n",
    "scraper.download_reports(report_list, save_folder=\"pdf_files\")  # 보고서 다운로드\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
